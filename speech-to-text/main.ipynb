{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collecting data\n",
    " Collecting data: The first step is to collect audio data in a suitable format for\n",
    "the task. The most common format is WAV, but other formats like MP3 or FLAC can\n",
    "also be used. The audio data should be representative of the speech patterns\n",
    "and accents of the intended audience. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.signal as sps\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Audio\n",
    "The audio data needs to be preprocessed to extract useful features and remove any noise or distortion that could interfere with the recognition process. One common technique for this is to use a Short-Time Fourier Transform (STFT) to break down the audio signal into its frequency components and then apply a noise reduction algorithm to filter out any unwanted noise. The resulting features can be represented as a spectrogram or a Mel-Frequency Cepstral Coefficient (MFCC) representation, which can be fed into the speech recognition model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the audio signal\n",
    "audio_file = 'path/to/audio/file.wav'\n",
    "y, sr = librosa.load(audio_file)\n",
    "\n",
    "# Set the window size and overlap for the STFT\n",
    "win_size = 1024\n",
    "hop_size = win_size // 4\n",
    "\n",
    "# Compute the STFT\n",
    "stft = librosa.stft(y, n_fft=win_size, hop_length=hop_size)\n",
    "\n",
    "# Compute the magnitude spectrogram\n",
    "mag_spec = np.abs(stft)\n",
    "\n",
    "# Compute the power spectrogram\n",
    "power_spec = mag_spec ** 2\n",
    "\n",
    "# Compute the noise floor from the power spectrogram\n",
    "noise_thresh = sps.mode(power_spec.ravel())[0]\n",
    "\n",
    "# Subtract the noise floor from the power spectrogram\n",
    "clean_spec = np.maximum(power_spec - noise_thresh, 0)\n",
    "\n",
    "# Reconstruct the cleaned audio signal\n",
    "clean_stft = mag_spec * np.exp(1j * np.angle(stft))\n",
    "clean_signal = librosa.istft(clean_stft, hop_length=hop_size)\n",
    "\n",
    "# Save the cleaned audio signal\n",
    "clean_file = 'path/to/cleaned/audio/file.wav'\n",
    "librosa.output.write_wav(clean_file, clean_signal, sr)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transcription\n",
    "To transcribe the speech, we need to use Automatic Speech Recognition (ASR) techniques. The ASR process involves several steps:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr\n",
    "\n",
    "# defining recognizer object\n",
    "r = sr.Recognizer()\n",
    "\n",
    "# loading audio file\n",
    "audio_file = sr.AudioFile('path/to/file.wav')\n",
    "\n",
    "# opening audio file\n",
    "with audio_file as source:\n",
    "    # reading audio data\n",
    "    audio_data = r.record(source)\n",
    "\n",
    "# transcribing audio data\n",
    "text = r.recognize_google(audio_data)\n",
    "print(text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
